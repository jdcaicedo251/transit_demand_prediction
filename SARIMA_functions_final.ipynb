{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "import itertools\n",
    "import matplotlib.dates as mdates\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use autocorrelation plot to decide differencing (d) and AR (p)\n",
    "# use partial autocorrelation plot to decide MA (q)\n",
    "# note: AR factors correct for slight under-differencing, MA factors correct for slight over-differencing\n",
    "\n",
    "def differencing_acf_pacf_plots(aggregated):\n",
    "    \"\"\"\n",
    "    Plots the data, autocorrelation plot, and partial \n",
    "    autocorrelation plot for the original series, first\n",
    "    order differencing, and second order differencing\n",
    "    Input:\n",
    "    - aggregated: Series or DataFrame of aggregated smartcard data\n",
    "    \"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(3, 3, figsize=(20,15))\n",
    "    axes[0, 0].plot(aggregated); axes[0, 0].set_title('Original Series')\n",
    "    plot_acf(aggregated, ax=axes[0, 1])\n",
    "    plot_pacf(aggregated, ax=axes[0, 2])\n",
    "\n",
    "    # 1st Differencing\n",
    "    axes[1, 0].plot(aggregated.diff()); axes[1, 0].set_title('1st Order Differencing')\n",
    "    plot_acf(aggregated.diff().dropna(), ax=axes[1, 1])\n",
    "    plot_pacf(aggregated.diff().dropna(), ax=axes[1, 2])\n",
    "\n",
    "    # 2nd Differencing\n",
    "    axes[2, 0].plot(aggregated.diff().diff()); axes[2, 0].set_title('2nd Order Differencing')\n",
    "    plot_acf(aggregated.diff().diff().dropna(), ax=axes[2, 1])\n",
    "    plot_pacf(aggregated.diff().diff().dropna(), ax=axes[2, 2])\n",
    "\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_residual_plots(test_and_predictions_TESTdata, test_and_predictions_COVIDdata, figure_title=''):\n",
    "    \"\"\"\n",
    "    Returns four plots: [1] line plot of the actual and predicted data from test period, \n",
    "    [2] line plot of the actual and predicted data from the COVID-19 period, and [3, 4] \n",
    "    residual plots for both (residual = prediction - observed)\n",
    "    \"\"\"\n",
    "    \n",
    "    fig, ax = plt.subplots(2, 2, sharey='row', figsize=(20, 15))\n",
    "    fig.suptitle(figure_title, fontsize=16)\n",
    "    \n",
    "    #July 2019 - Feb 2020\n",
    "    ax[0,0].plot(test_and_predictions_TESTdata['observed'], label='observed')\n",
    "    ax[0,0].plot(test_and_predictions_TESTdata['predictions'], label='predicted')\n",
    "    ax[0,0].set(xlabel=\"Date\",\n",
    "           ylabel=\"Ridership\",\n",
    "           title='July 2019-Feb 2020')\n",
    "    date_form = mdates.DateFormatter(\"%b-%d-%y\")\n",
    "    ax[0,0].xaxis.set_major_formatter(date_form)\n",
    "    ax[0,0].legend()\n",
    "    \n",
    "    errors = test_and_predictions_TESTdata['predictions'] - test_and_predictions_TESTdata['observed']\n",
    "    ax[1,0].scatter(test_and_predictions_TESTdata.index, pd.DataFrame(errors).set_index(test_and_predictions_TESTdata.index))\n",
    "    ax[1,0].plot(test_and_predictions_TESTdata.index, np.zeros(len(test_and_predictions_TESTdata.index)))\n",
    "    ax[1,0].set(xlabel=\"Date\",\n",
    "           ylabel=\"Residuals\",\n",
    "           title= 'Residual Distribution')\n",
    "    ax[1,0].xaxis.set_major_formatter(date_form)\n",
    "    \n",
    "    #March 2020 - April 2021\n",
    "    ax[0,1].plot(test_and_predictions_COVIDdata['observed'], label='observed')\n",
    "    ax[0,1].plot(test_and_predictions_COVIDdata['predictions'], label='predicted')\n",
    "    ax[0,1].set(xlabel=\"Date\",\n",
    "           ylabel=\"Ridership\",\n",
    "           title='March 2020-April 2021')\n",
    "    ax[0,1].xaxis.set_major_formatter(date_form)\n",
    "    ax[0,1].legend()\n",
    "    \n",
    "    errors = test_and_predictions_COVIDdata['predictions'] - test_and_predictions_COVIDdata['observed']\n",
    "    ax[1,1].scatter(test_and_predictions_COVIDdata.index, pd.DataFrame(errors).set_index(test_and_predictions_COVIDdata.index))\n",
    "    ax[1,1].plot(test_and_predictions_COVIDdata.index, np.zeros(len(test_and_predictions_COVIDdata.index)))\n",
    "    ax[1,1].set(xlabel=\"Date\",\n",
    "           ylabel=\"Residuals\",\n",
    "           title= 'Residual Distribution')\n",
    "    ax[1,1].xaxis.set_major_formatter(date_form)\n",
    "            \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rolling ARIMA/SARIMA functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to apply ARIMA to aggregated dataset, returns plot of predicted vs actual test dataset\n",
    "\n",
    "def applyARIMA_rolling(agg_training, agg_test, order=(2,0,0), plot=True, plot_title='', resid_plot=True):\n",
    "    \"\"\"\n",
    "    Simulates one-step rolling forecasts using statsmodel ARIMA model\n",
    "    Process: Forecasts one time-step ahead, adds the observed value for that time-step to training data, then\n",
    "        predicts the next time-step. Parameters of ARIMA model change with each time-step. Future predictions \n",
    "        are made using observed data.\n",
    "    Inputs:\n",
    "    - agg_training: values to use for training the ARIMA model\n",
    "    - agg_test: values to predict for using the trained ARIMA model\n",
    "    - order: p,d,q for the statsmodel ARIMA function\n",
    "    - plot: returns a line plot of actual and predicted data\n",
    "    - plot_title: title for plot\n",
    "    - resid_plot: returns a residual plot (residual = predicted - actual)\n",
    "    \"\"\"\n",
    "    \n",
    "    train = agg_training.values\n",
    "    test = agg_test.values\n",
    "    history = [x for x in train]\n",
    "    predictions = list()\n",
    "    if agg_test.index[0] == datetime(2020,3,1):\n",
    "        for t in range(len(test) + 31 + 29):\n",
    "            model = ARIMA(history, order=order)\n",
    "            model_fit = model.fit()\n",
    "            output = model_fit.forecast()\n",
    "            yhat = output[0]\n",
    "            predictions.append(yhat)\n",
    "            if t < 60:\n",
    "                history.append(np.array([yhat]))\n",
    "            else:\n",
    "                obs = test[t-60]\n",
    "                history.append(obs)\n",
    "        test_and_predictions = pd.DataFrame({'observed': test.flatten(), 'predictions': predictions[60:]}).set_index(agg_test.index)\n",
    "    else:\n",
    "        for t in range(len(test)):\n",
    "            model = ARIMA(history, order=order)\n",
    "            model_fit = model.fit()\n",
    "            output = model_fit.forecast()\n",
    "            yhat = output[0]\n",
    "            predictions.append(yhat)\n",
    "            obs = test[t]\n",
    "            history.append(obs)\n",
    "        test_and_predictions = pd.DataFrame({'observed': test.flatten(), 'predictions': predictions}).set_index(agg_test.index)\n",
    "    \n",
    "    if plot==True:\n",
    "        fig, ax = plt.subplots(figsize=(10, 8))\n",
    "        ax.plot(test_and_predictions['observed'], label='observed')\n",
    "        ax.plot(test_and_predictions['predictions'], label='prediction')\n",
    "        ax.set(xlabel=\"Date\",\n",
    "               ylabel=\"Ridership\",\n",
    "               title=plot_title)\n",
    "        date_form = mdates.DateFormatter(\"%b-%d\")\n",
    "        ax.xaxis.set_major_formatter(date_form)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    if resid_plot==True:\n",
    "        errors = test_and_predictions['predictions'] - test_and_predictions['observed']\n",
    "        fig, ax = plt.subplots(figsize=(10,8))\n",
    "        ax.scatter(agg_test.index, pd.DataFrame(errors).set_index(agg_test.index))\n",
    "        ax.plot(agg_test.index, np.zeros(len(agg_test.index)))\n",
    "        date_form = mdates.DateFormatter(\"%b-%d\")\n",
    "        ax.xaxis.set_major_formatter(date_form)\n",
    "        plt.show()\n",
    "        \n",
    "    return {'observed and predicted values': test_and_predictions, 'model object': model_fit}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to apply SARIMA to aggregated dataset, returns plot of predicted vs actual test dataset\n",
    "\n",
    "def applySARIMA_rolling(agg_training, agg_test, order=(2,0,0), seasonal_order=(0,0,0,0), plot=True, plot_title='', resid_plot=True):\n",
    "    \"\"\"\n",
    "    Simulates one-step rolling forecasts using statsmodel SARIMA model\n",
    "    Process: Forecasts one time-step ahead, adds the observed value for that time-step to training data, \n",
    "        and fits a new model to predict the next time-step. Parameters of the SARIMA model change with\n",
    "        each time-step. Future predictions are made using observed data.\n",
    "    Inputs:\n",
    "    - agg_training: values to use for training the ARIMA model\n",
    "    - agg_test: values to predict for using the trained ARIMA model\n",
    "    - order: p,d,q for the statsmodel ARIMA function\n",
    "    - seasonal_order: P,D,Q,m for the statsmodel SARIMA function\n",
    "    - plot: returns a line plot of actual and predicted data\n",
    "    - plot_title: title for plot\n",
    "    - resid_plot: returns a residual plot (residual = predicted - actual)\n",
    "    \"\"\"\n",
    "    \n",
    "    train = agg_training.values\n",
    "    test = agg_test.values\n",
    "    history = [x for x in train]\n",
    "    predictions = list()\n",
    "    if agg_test.index[0] == datetime(2020,3,1):\n",
    "        for t in range(len(test) + 31 + 29):\n",
    "            #pdb.set_trace()\n",
    "            model = SARIMAX(history, order=order, seasonal_order=seasonal_order, initialization='approximate_diffuse')\n",
    "            model_fit = model.fit()\n",
    "            output = model_fit.forecast()\n",
    "            yhat = output[0]\n",
    "            predictions.append(yhat)\n",
    "            if t < 60:\n",
    "                history.append(np.array([yhat]))\n",
    "            else:\n",
    "                obs = test[t-60]\n",
    "                history.append(obs)\n",
    "        test_and_predictions = pd.DataFrame({'observed': test.flatten(), 'predictions': predictions[60:]}).set_index(agg_test.index)\n",
    "    else:\n",
    "        for t in range(len(test)):\n",
    "            model = SARIMAX(history, order=order, seasonal_order=seasonal_order)\n",
    "            model_fit = model.fit() \n",
    "            output = model_fit.forecast()\n",
    "            yhat = output[0]\n",
    "            predictions.append(yhat)\n",
    "            obs = test[t]\n",
    "            history.append(obs)\n",
    "        test_and_predictions = pd.DataFrame({'observed': test.flatten(), 'predictions': predictions}).set_index(agg_test.index)\n",
    "    \n",
    "    if plot==True:\n",
    "        fig, ax = plt.subplots(figsize=(10, 8))\n",
    "        ax.plot(test_and_predictions['observed'], label='observed')\n",
    "        ax.plot(test_and_predictions['predictions'], label='prediction')\n",
    "        ax.set(xlabel=\"Date\",\n",
    "               ylabel=\"Ridership\",\n",
    "               title=plot_title)\n",
    "        date_form = mdates.DateFormatter(\"%b-%d\")\n",
    "        ax.xaxis.set_major_formatter(date_form)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    if resid_plot==True:\n",
    "        errors = test_and_predictions['predictions'] - test_and_predictions['observed']\n",
    "        fig, ax = plt.subplots(figsize=(10,8))\n",
    "        ax.scatter(agg_test.index, pd.DataFrame(errors).set_index(agg_test.index))\n",
    "        ax.plot(agg_test.index, np.zeros(len(agg_test.index)))\n",
    "        date_form = mdates.DateFormatter(\"%b-%d\")\n",
    "        ax.xaxis.set_major_formatter(date_form)\n",
    "        plt.show()\n",
    "    \n",
    "    return {'observed and predicted values': test_and_predictions, 'model object': model_fit}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Static ARIMA/SARIMA functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applyARIMA_static(agg_training, agg_test, order=(2,0,0), plot=True, plot_title='', resid_plot=True):\n",
    "    \"\"\"\n",
    "    Makes multi-step predictions using statsmodel ARIMA model\n",
    "    Process: Fits one ARIMA model using the input training data and uses fitted model\n",
    "        to make multi-step out-of-sample predictions for test data. Parameters of model do \n",
    "        not change. Future predictions are made using past predictions.\n",
    "    Inputs:\n",
    "    - agg_training: aggregated values to use for training the ARIMA model\n",
    "    - agg_test: aggregated values to predict for using the trained ARIMA model\n",
    "    - order: p,d,q for the statsmodel ARIMA function\n",
    "    - plot: returns a line plot of actual and predicted data\n",
    "    - plot_title: title for plot\n",
    "    - resid_plot: returns a residual plot (residual = predicted - actual)\n",
    "    \"\"\"\n",
    "    \n",
    "    train = agg_training.values\n",
    "    test = agg_test.values\n",
    "    model = ARIMA(train, order=order)\n",
    "    model_fit = model.fit()\n",
    "    \n",
    "    if agg_test.index[0] == datetime(2020,3,1):\n",
    "        predictions = model_fit.forecast(steps=len(test) + 31 + 29)\n",
    "        predictions = predictions[60:]\n",
    "    else:\n",
    "        predictions = model_fit.forecast(steps=len(test))\n",
    "    test_and_predictions = pd.DataFrame({'observed': test.flatten(), 'predictions': predictions}).set_index(agg_test.index)\n",
    "    \n",
    "    if plot==True:\n",
    "        fig, ax = plt.subplots(figsize=(10, 8))\n",
    "        ax.plot(test_and_predictions['observed'], label='observed')\n",
    "        ax.plot(test_and_predictions['predictions'], label='prediction')\n",
    "        ax.set(xlabel=\"Date\",\n",
    "               ylabel=\"Ridership\",\n",
    "               title=plot_title)\n",
    "        date_form = mdates.DateFormatter(\"%b-%d\")\n",
    "        ax.xaxis.set_major_formatter(date_form)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    if resid_plot==True:\n",
    "        errors = test_and_predictions['predictions'] - test_and_predictions['observed']\n",
    "        fig, ax = plt.subplots(figsize=(10,8))\n",
    "        ax.scatter(agg_test.index, pd.DataFrame(errors).set_index(agg_test.index))\n",
    "        ax.plot(agg_test.index, np.zeros(len(agg_test.index)))\n",
    "        date_form = mdates.DateFormatter(\"%b-%d\")\n",
    "        ax.xaxis.set_major_formatter(date_form)\n",
    "        plt.show()\n",
    "        \n",
    "    return {'observed and predicted values': test_and_predictions, 'model object': model_fit}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applySARIMA_static(agg_training, agg_test, order=(2,0,0), seasonal_order=(0,0,0,0), plot=True, plot_title='', resid_plot=True):\n",
    "    \"\"\"\n",
    "    Makes multi-step predictions using statsmodel SARIMA model\n",
    "    Process: Fits one SARIMA model using the input training data and uses fitted model\n",
    "        to make multi-step out-of-sample predictions for test data. Parameters of model \n",
    "        do not change. Future predictions are made using past predictions. \n",
    "    Inputs:\n",
    "    - agg_training: aggregated values to use for training the ARIMA model\n",
    "    - agg_test: aggregated values to predict for using the trained ARIMA model\n",
    "    - order: p,d,q for the statsmodel SARIMA function\n",
    "    - seasonal_order: P,D,Q,m for the statsmodel SARIMA function\n",
    "    - plot: returns a line plot of actual and predicted data\n",
    "    - plot_title: title for plot\n",
    "    - resid_plot: returns a residual plot (residual = predicted - actual)\n",
    "    \"\"\"\n",
    "    \n",
    "    train = agg_training.values\n",
    "    test = agg_test.values\n",
    "    model = SARIMAX(train, order=order, seasonal_order=seasonal_order)\n",
    "    model_fit = model.fit()\n",
    "    \n",
    "    if agg_test.index[0] == datetime(2020,3,1):\n",
    "        predictions = model_fit.forecast(steps=len(test) + 31 + 29)\n",
    "        predictions = predictions[60:]\n",
    "    else:\n",
    "        predictions = model_fit.forecast(steps=len(test))\n",
    "    test_and_predictions = pd.DataFrame({'observed': test.flatten(), 'predictions': predictions}).set_index(agg_test.index)\n",
    "    \n",
    "    if plot==True:\n",
    "        fig, ax = plt.subplots(figsize=(10, 8))\n",
    "        ax.plot(test_and_predictions['observed'], label='observed')\n",
    "        ax.plot(test_and_predictions['predictions'], label='prediction')\n",
    "        ax.set(xlabel=\"Date\",\n",
    "               ylabel=\"Ridership\",\n",
    "               title=plot_title)\n",
    "        date_form = mdates.DateFormatter(\"%b-%d\")\n",
    "        ax.xaxis.set_major_formatter(date_form)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    if resid_plot==True:\n",
    "        errors = test_and_predictions['predictions'] - test_and_predictions['observed']\n",
    "        fig, ax = plt.subplots(figsize=(10,8))\n",
    "        ax.scatter(agg_test.index, pd.DataFrame(errors).set_index(agg_test.index))\n",
    "        ax.plot(agg_test.index, np.zeros(len(agg_test.index)))\n",
    "        date_form = mdates.DateFormatter(\"%b-%d\")\n",
    "        ax.xaxis.set_major_formatter(date_form)\n",
    "        plt.show()\n",
    "    return {'observed and predicted values': test_and_predictions, 'model object': model_fit}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intermediate SARIMA functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applySARIMA_intermediate(agg_training, agg_test, order=(2,0,0), seasonal_order=(0,0,0,0), agg_type='daily', plot=True, plot_title='', resid_plot=True):\n",
    "    \"\"\"\n",
    "    Simulates multi-step rolling forecasts using statsmodel SARIMA model\n",
    "    Process: Fits one SARIMA model using the input training data, predicts multiple timesteps at once,\n",
    "        adds the observed values of the predicted timesteps to historical data, and then predicts the next\n",
    "        multiple timesteps. Parameters of the SARIMA model do not change. Future predictions are made using\n",
    "        a mix of past predictions and observed data.\n",
    "    Inputs:\n",
    "    - agg_training: aggregated values to use for training the SARIMA model\n",
    "    - agg_test: aggregated values to predict for using the trained SARIMA model\n",
    "    - order: p,d,q for the statsmodel SARIMA function\n",
    "    - seasonal_order: P,D,Q,m for the statsmodel SARIMA function\n",
    "    - agg_type: timestep of aggregation (15 min, daily, weekly)\n",
    "    - plot: returns a line plot of actual and predicted data\n",
    "    - plot_title: title for plot\n",
    "    - resid_plot: returns a residual plot (residual = predicted - actual)\n",
    "    \"\"\"\n",
    "    \n",
    "    train = agg_training\n",
    "    test = agg_test\n",
    "    predictions = []\n",
    "    \n",
    "    if agg_type=='15 min':\n",
    "        pred_window = 4 # makes predictions for the next hour at a time\n",
    "    elif agg_type=='daily':\n",
    "        pred_window = 7 # makes predictions for the next week at a time\n",
    "    elif agg_type=='weekly':\n",
    "        pred_window = 4 # makes predictions for the next month at a time\n",
    "    \n",
    "    model = SARIMAX(train, order=order, seasonal_order=seasonal_order)\n",
    "    model_fit = model.fit()\n",
    "    for x in model_fit.forecast(pred_window).tolist():\n",
    "        predictions.append(x)\n",
    "    \n",
    "    k=0\n",
    "    while pred_window*k+(pred_window-1) < len(test.values):\n",
    "        week_startdate = test.index[pred_window*k].strftime('%Y-%m-%d')\n",
    "        week_enddate = test.index[pred_window*k+(pred_window-1)].strftime('%Y-%m-%d')\n",
    "        model_fit = model_fit.append(test[week_startdate:week_enddate])\n",
    "        for x in model_fit.forecast(pred_window).tolist():\n",
    "            predictions.append(x)\n",
    "        k=k+1\n",
    "    \n",
    "    test_and_predictions = pd.DataFrame({'observed': test.values.flatten(), 'predictions': predictions[:len(test.values)]}).set_index(test.index)\n",
    "    \n",
    "    if plot==True:\n",
    "        fig, ax = plt.subplots(figsize=(10, 8))\n",
    "        ax.plot(test_and_predictions['observed'], label='observed')\n",
    "        ax.plot(test_and_predictions['predictions'], label='prediction')\n",
    "        ax.set(xlabel=\"Date\",\n",
    "               ylabel=\"Ridership\",\n",
    "               title=plot_title)\n",
    "        date_form = mdates.DateFormatter(\"%b-%d\")\n",
    "        ax.xaxis.set_major_formatter(date_form)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    if resid_plot==True:\n",
    "        errors = test_and_predictions['predictions'] - test_and_predictions['observed']\n",
    "        fig, ax = plt.subplots(figsize=(10,8))\n",
    "        ax.scatter(agg_test.index, pd.DataFrame(errors).set_index(agg_test.index))\n",
    "        ax.plot(agg_test.index, np.zeros(len(agg_test.index)))\n",
    "        date_form = mdates.DateFormatter(\"%b-%d\")\n",
    "        ax.xaxis.set_major_formatter(date_form)\n",
    "        plt.show()\n",
    "        \n",
    "    return {'observed and predicted values': test_and_predictions, 'model object': model_fit}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_random_sample_from_parameters(hyperparam_dict, size = 10):\n",
    "    ''' Returns a DataFrame with len size of random draws from the grid. \n",
    "    Input:\n",
    "    - hyperparam_dict: dictionary with keys p/d/q and P/D/Q/m, if applicable \n",
    "    - size: Number of random draws\n",
    "    '''\n",
    "    if len(hyperparam_dict)==3:\n",
    "        p = hyperparam_dict['p']\n",
    "        d = hyperparam_dict['d']\n",
    "        q = hyperparam_dict['q']\n",
    "        all_param_combinations = itertools.product(p,d,q)\n",
    "        column_labels = ['p','d','q']\n",
    "    if len(hyperparam_dict)==7:\n",
    "        p = hyperparam_dict['p']; d = hyperparam_dict['d']; q = hyperparam_dict['q']\n",
    "        P = hyperparam_dict['P']\n",
    "        D = hyperparam_dict['D']\n",
    "        Q = hyperparam_dict['Q']\n",
    "        m = hyperparam_dict['m']\n",
    "        all_param_combinations = list(itertools.product(p,d,q,P,D,Q,m))\n",
    "        column_labels = ['p','d','q','P','D','Q','m']\n",
    "        \n",
    "    grid = pd.DataFrame(all_param_combinations, columns=column_labels)\n",
    "    grid_rands = grid.iloc[np.random.choice(grid.index, size, replace=False),:] \n",
    "    return grid_rands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(hyperparam_dict, agg_training, agg_test, model='ARIMA', model_type='intermediate', agg_type='daily', iterations = 10):\n",
    "    \"\"\"\n",
    "    Returns best hyperparameter combination through gridsearch\n",
    "    Inputs:\n",
    "    - hyperparam_dict: dictionary with keys p/d/q and P/D/Q/m, if applicable\n",
    "    - agg_training: aggregated values to use for training the S/ARIMA model\n",
    "    - agg_test: aggregated values to predict for using the trained S/ARIMA model\n",
    "    - model: ARIMA or SARIMA\n",
    "    - model_type: rolling, static, or intermediate\n",
    "    - agg_type: timestep of aggregation (15 min, daily, weekly)\n",
    "    - iterations: number of hyperparameter combinations to try\n",
    "    \"\"\"\n",
    "    \n",
    "    random_grid = create_random_sample_from_parameters(hyperparam_dict, size = iterations)\n",
    "    score_list = []\n",
    "    normBIC_list = []\n",
    "    MAPE_list = []\n",
    "    \n",
    "    for x in np.arange(0,len(random_grid)):\n",
    "        #print(x)\n",
    "        if model=='ARIMA':\n",
    "            order = random_grid.iloc[x,:]\n",
    "            try:\n",
    "                if model_type=='rolling':\n",
    "                    output = applyARIMA_rolling(agg_training,agg_test,order=order,plot=False,resid_plot=False)\n",
    "                elif model_type=='static':\n",
    "                    output = applyARIMA_static(agg_training,agg_test,order=order,plot=False,resid_plot=False)\n",
    "                \n",
    "                test_and_predictions = output['observed and predicted values']\n",
    "                \n",
    "                corr = test_and_predictions.corr().iloc[1,0] ** 2\n",
    "                score_list.append(corr)\n",
    "                MSE = mean_squared_error(test_and_predictions['observed'],test_and_predictions['predictions'])\n",
    "                normBIC = np.log(MSE) + sum(order+1)*np.log(output['model object'].nobs)/output['model object'].nobs\n",
    "                normBIC_list.append(normBIC)\n",
    "                MAPE_list.append(MAPE(test_and_predictions))\n",
    "                if normBIC == np.nanmin(normBIC_list):\n",
    "                    final_hp = order\n",
    "                    final_output = output\n",
    "            except:\n",
    "                score_list.append(np.nan)\n",
    "                normBIC_list.append(np.nan)\n",
    "                MAPE_list.append(np.nan)\n",
    "                continue\n",
    "        elif model=='SARIMA':\n",
    "            order = random_grid.iloc[x,0:3]\n",
    "            s_order = random_grid.iloc[x,3:8]\n",
    "            try:\n",
    "                if model_type=='rolling':\n",
    "                    output = applySARIMA_rolling(agg_training,agg_test,order=order,seasonal_order=s_order,plot=False,resid_plot=False)\n",
    "                elif model_type=='static':\n",
    "                    output = applySARIMA_static(agg_training,agg_test,order=order,seasonal_order=s_order,plot=False,resid_plot=False)\n",
    "                elif model_type=='intermediate':\n",
    "                    output = applySARIMA_intermediate(agg_training, agg_test, order=order, seasonal_order=s_order, agg_type=agg_type, plot=False, resid_plot=False)\n",
    "                \n",
    "                test_and_predictions = output['observed and predicted values']\n",
    "                \n",
    "                try:\n",
    "                    MSE = mean_squared_error(test_and_predictions['observed'],test_and_predictions['predictions'])\n",
    "                    normBIC = np.log(MSE) + sum(order+1)*np.log(output['model object'].nobs)/output['model object'].nobs\n",
    "                    normBIC_list.append(normBIC)\n",
    "                    MAPE_list.append(MAPE(test_and_predictions))\n",
    "                    corr = test_and_predictions.corr().iloc[1,0] ** 2\n",
    "                    score_list.append(corr)\n",
    "                    if normBIC == np.nanmin(normBIC_list):\n",
    "                        final_hp = [order, s_order]\n",
    "                        final_output = output\n",
    "                except ValueError: \n",
    "                    normBIC_list.append(np.nan)\n",
    "                    MAPE_list.append(np.nan)\n",
    "                    score_list.append(np.nan)\n",
    "                    continue\n",
    "            except:\n",
    "                normBIC_list.append(np.nan)\n",
    "                MAPE_list.append(np.nan)\n",
    "                score_list.append(np.nan)\n",
    "                continue\n",
    "    \n",
    "    results = random_grid\n",
    "    results['R-squared'] = score_list\n",
    "    results['normalized BIC'] = normBIC_list\n",
    "    results['MAPE'] = MAPE_list\n",
    "    \n",
    "    return {'final hyperparams': final_hp, \n",
    "            'observed and predicted values': final_output['observed and predicted values'],\n",
    "            'model object': final_output['model object'],\n",
    "            'gridsearch results': results}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAPE(test_and_predictions):\n",
    "    predictions = test_and_predictions['predictions']\n",
    "    for i in np.arange(0,len(predictions)-1):\n",
    "        if predictions[i] < 0:\n",
    "            predictions[i] = 0\n",
    "    data = pd.DataFrame({'observed': test_and_predictions['observed'],\n",
    "                        'predictions': predictions})\n",
    "    data = data[data['observed'] != 0]\n",
    "    return np.mean(np.abs((data['observed'] - data['predictions']) / data['observed'])) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VAPE(test_and_predictions):\n",
    "    predictions = test_and_predictions['predictions']\n",
    "    for i in np.arange(0,len(predictions)-1):\n",
    "        if predictions[i] < 0:\n",
    "            predictions[i] = 0\n",
    "    errors = test_and_predictions['observed'] - predictions\n",
    "    return np.mean((errors - np.mean(errors))**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE(test_and_predictions):\n",
    "    predictions = test_and_predictions['predictions']\n",
    "    for i in np.arange(0,len(predictions)-1):\n",
    "        if predictions[i] < 0:\n",
    "            predictions[i] = 0\n",
    "    data = test_and_predictions\n",
    "    data = data[data['observed'] != 0]\n",
    "    return np.sqrt(np.mean((data['observed'] - data['predictions'])**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automating process for one station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rollingSARIMA_results(cleaned_data_onestation, hyperparam_dict, agg_type='daily', log_transform=True):\n",
    "    \"\"\"\n",
    "    Takes data from one station, aggregates it (15 min, daily, or weekly), splits it into train/test/covid sets, \n",
    "    makes predictions using rolling SARIMA model\n",
    "    Returns line plots of observed vs predicted values, and residual plots\n",
    "    Inputs:\n",
    "    - cleaned_data_onestation: one column from transactions_clean.csv. load csv into DataFrame, convert the 'timestamp'\n",
    "    column to Timestamp type, and make it the index\n",
    "    - hyperparam_dict: dictionary with keys p/d/q and P/D/Q/m, if applicable\n",
    "    - agg_type: timestep of aggregation (15 min, daily, weekly)\n",
    "    - log_transform: if True, the data will be log-transformed before the model is applied\n",
    "    \"\"\"\n",
    "    \n",
    "    fifteen_min = cleaned_data_onestation\n",
    "    daily = cleaned_data_onestation.resample('D').sum()\n",
    "    weekly = cleaned_data_onestation.resample('W').sum()\n",
    "    \n",
    "    if agg_type=='15 min':\n",
    "        train = fifteen_min.loc['2018-01-01':'2019-12-31'] # August 2015 - June 2019\n",
    "        test = fifteen_min.loc['2020-01-01':'2020-02-29'] # July 2019 - Feb 2020\n",
    "        covid = fifteen_min.loc['2020-03-01':'2020-05-31'] # March 2020 - April 2021\n",
    "    elif agg_type=='daily':\n",
    "        train = daily.loc['2018-01-01':'2019-12-31']\n",
    "        test = daily.loc['2020-01-01':'2020-02-29']\n",
    "        covid = daily.loc['2020-03-01':'2020-05-31']\n",
    "    elif agg_type=='weekly':\n",
    "        train = weekly.loc['2018-01-01':'2019-12-31']\n",
    "        test = weekly.loc['2020-01-01':'2020-02-29']\n",
    "        covid = weekly.loc['2020-03-01':'2020-05-31']\n",
    "    else:\n",
    "        print('options for agg_type: 15 min, daily, weekly')\n",
    "        return\n",
    "    \n",
    "    if log_transform==True:\n",
    "        train = np.log(train)\n",
    "        test = np.log(test)\n",
    "        covid = np.log(covid)\n",
    "    \n",
    "    results_test = grid_search(hyperparam_dict, train, test, model='SARIMA', model_type='rolling', iterations = 10)\n",
    "    best_order = results_test['final hyperparams'][0].values\n",
    "    best_s_order = results_test['final hyperparams'][1].values\n",
    "    \n",
    "    results_covid = applySARIMA_rolling(train, covid, order=best_order, seasonal_order=best_s_order, plot=False, resid_plot=False)\n",
    "    \n",
    "    fig_title = cleaned_data_onestation.columns[0] + '\\nSARIMA' + str(best_order) + str(best_s_order)\n",
    "    prediction_residual_plots(results_test['observed and predicted values'], results_covid['observed and predicted values'], figure_title=fig_title)\n",
    "    \n",
    "    return {'final hyperparams': results_test['final hyperparams'],\n",
    "           'predicted values (test)': results_test['observed and predicted values'],\n",
    "           'model object (test)': results_test['model object'],\n",
    "           'gridsearch results': results_test['gridsearch results'],\n",
    "           'predicted values (COVID)': results_covid['observed and predicted values'],\n",
    "           'model object (COVID)': results_covid['model object']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def staticSARIMA_results(cleaned_data_onestation, hyperparam_dict, agg_type='daily', log_transform=True):\n",
    "    \"\"\"\n",
    "    Takes data from one station, aggregates it (15 min, daily, or weekly), splits it into train/test/covid sets, \n",
    "    makes predictions using static SARIMA model\n",
    "    Returns line plots of observed vs predicted values, and residual plots\n",
    "    Inputs:\n",
    "    - cleaned_data_onestation: one column from transactions_clean.csv. load csv into DataFrame, convert the 'timestamp'\n",
    "    column to Timestamp type, and make it the index\n",
    "    - hyperparam_dict: dictionary with keys p/d/q and P/D/Q/m, if applicable\n",
    "    - agg_type: timestep of aggregation (15 min, daily, weekly)\n",
    "    - log_transform: if True, the data will be log-transformed before the model is applied\n",
    "    \"\"\"\n",
    "    \n",
    "    fifteen_min = cleaned_data_onestation\n",
    "    daily = cleaned_data_onestation.resample('D').sum()\n",
    "    weekly = cleaned_data_onestation.resample('W').sum()\n",
    "    \n",
    "    if agg_type=='15 min':\n",
    "        train = fifteen_min.loc['2015-08-01':'2019-06-30'] # August 2015 - June 2019\n",
    "        test = fifteen_min.loc['2019-07-01':'2020-02-29'] # July 2019 - Feb 2020\n",
    "        covid = fifteen_min.loc['2020-03-01':'2021-04-30'] # March 2020 - April 2021\n",
    "    elif agg_type=='daily':\n",
    "        train = daily.loc['2015-08-01':'2019-06-30']\n",
    "        test = daily.loc['2019-07-01':'2020-02-29']\n",
    "        covid = daily.loc['2020-03-01':'2021-04-30']\n",
    "    elif agg_type=='weekly':\n",
    "        train = weekly.loc['2015-08-01':'2019-06-30']\n",
    "        test = weekly.loc['2019-07-01':'2020-02-29']\n",
    "        covid = weekly.loc['2020-03-01':'2021-04-30']\n",
    "    else:\n",
    "        print('options for agg_type: 15 min, daily, weekly')\n",
    "        return\n",
    "    \n",
    "    if log_transform==True:\n",
    "        train = np.log(train+1)\n",
    "        test = np.log(test+1)\n",
    "        covid = np.log(covid+1)\n",
    "    \n",
    "    results_test = grid_search(hyperparam_dict, train, test, model='SARIMA', model_type='static', iterations = 10)\n",
    "    best_order = results_test['final hyperparams'][0].values\n",
    "    best_s_order = results_test['final hyperparams'][1].values\n",
    "    \n",
    "    results_covid = applySARIMA_static(train, covid, order=best_order, seasonal_order=best_s_order, plot=False, resid_plot=False)\n",
    "    \n",
    "    fig_title = cleaned_data_onestation.columns[0] + '\\nSARIMA' + str(best_order) + str(best_s_order)\n",
    "    prediction_residual_plots(np.exp(results_test['observed and predicted values']), np.exp(results_covid['observed and predicted values']), figure_title=fig_title)\n",
    "    \n",
    "    return {'final hyperparams': results_test['final hyperparams'],\n",
    "           'predicted values (test)': results_test['observed and predicted values'],\n",
    "           'model object (test)': results_test['model object'],\n",
    "           'gridsearch results': results_test['gridsearch results'],\n",
    "           'predicted values (COVID)': results_covid['observed and predicted values'],\n",
    "           'model object (COVID)': results_covid['model object']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intermediateSARIMA_results(cleaned_data_onestation, hyperparam_dict, agg_type='daily', log_transform=True):\n",
    "    \"\"\"\n",
    "    Takes data from one station, aggregates it (15 min, daily, or weekly), splits it into train/test/covid sets, \n",
    "    makes predictions using intermediate SARIMA model\n",
    "    Returns line plots of observed vs predicted values, and residual plots\n",
    "    Inputs:\n",
    "    - cleaned_data_onestation: one column from transactions_clean.csv. load csv into DataFrame, convert the 'timestamp'\n",
    "    column to Timestamp type, and make it the index\n",
    "    - hyperparam_dict: dictionary with keys p/d/q and P/D/Q/m, if applicable\n",
    "    - agg_type: timestep of aggregation (15 min, daily, weekly)\n",
    "    - log_transform: if True, the data will be log-transformed before the model is applied\n",
    "    \"\"\"\n",
    "    \n",
    "    fifteen_min = cleaned_data_onestation\n",
    "    daily = cleaned_data_onestation.resample('D').sum()\n",
    "    weekly = cleaned_data_onestation.resample('W').sum()\n",
    "    \n",
    "    if agg_type=='15 min':\n",
    "        train = fifteen_min.loc['2015-08-01':'2019-06-30'] # August 2015 - June 2019\n",
    "        test = fifteen_min.loc['2019-07-01':'2020-02-29'] # July 2019 - Feb 2020\n",
    "        covid = fifteen_min.loc['2020-03-01':'2021-04-30'] # March 2020 - April 2021\n",
    "    elif agg_type=='daily':\n",
    "        train = daily.loc['2015-08-01':'2019-06-30']\n",
    "        test = daily.loc['2019-07-01':'2020-02-29']\n",
    "        covid = daily.loc['2020-03-01':'2021-04-30']\n",
    "    elif agg_type=='weekly':\n",
    "        train = weekly.loc['2015-08-01':'2019-06-30']\n",
    "        test = weekly.loc['2019-07-01':'2020-02-29']\n",
    "        covid = weekly.loc['2020-03-01':'2021-04-30']\n",
    "    else:\n",
    "        print('options for agg_type: 15 min, daily, weekly')\n",
    "        return\n",
    "    \n",
    "    if log_transform==True:\n",
    "        train = np.log(train+1)\n",
    "        test = np.log(test+1)\n",
    "        covid = np.log(covid+1)\n",
    "    \n",
    "    results_test = grid_search(hyperparam_dict, train, test, model='SARIMA', model_type='intermediate', agg_type='weekly',iterations = 10)\n",
    "    best_order = results_test['final hyperparams'][0].values\n",
    "    best_s_order = results_test['final hyperparams'][1].values\n",
    "    final_hyperparams = results_test['final hyperparams']\n",
    "    test_and_predictions_test = results_test['observed and predicted values']\n",
    "    \n",
    "    #del(results_test)\n",
    "    \n",
    "    results_covid = applySARIMA_intermediate(train, pd.concat([test,covid]), order=best_order, seasonal_order=best_s_order, agg_type=agg_type, plot=False, resid_plot=False)\n",
    "    \n",
    "    fig_title = cleaned_data_onestation.columns[0] + '\\nSARIMA' + str(best_order) + str(best_s_order)\n",
    "    prediction_residual_plots(np.exp(results_test['observed and predicted values']), np.exp(results_covid['observed and predicted values']['2020-03-01':'2021-04-30']), figure_title=fig_title)\n",
    "    \n",
    "    return {'final hyperparams': results_test['final hyperparams'],\n",
    "           'predicted values (test)': results_test['observed and predicted values'],\n",
    "           'model object (test)': results_test['model object'],\n",
    "           'gridsearch results': results_test['gridsearch results'],\n",
    "           'predicted values (COVID)': results_covid['observed and predicted values'],\n",
    "           'model object (COVID)': results_covid['model object']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Timestamp index for transactions_cleaned.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports transactions_clean.csv into DataFrame, changes 'timestamp' column to type Timestamp, and makes it the index of \n",
    "#DataFrame\n",
    "\n",
    "#cleaned_data = pd.read_csv('transactions_clean.csv')\n",
    "\n",
    "#timestamp_datetimes = []\n",
    "#for i in range(0,len(cleaned_data['timestamp'])):\n",
    "#    timestamp_string = cleaned_data['timestamp'][i]\n",
    "#    timestamp_datetimes.append(datetime.strptime(timestamp_string, '%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "#cleaned_data['timestamp'] = timestamp_datetimes\n",
    "#cleaned_data = cleaned_data.set_index('timestamp')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
