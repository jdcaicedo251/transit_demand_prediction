{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "\n",
    "import data \n",
    "import utils\n",
    "import pmdarima as pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'output/arima'\n",
    "data_directory = 'data'\n",
    "aggregation = 'day'\n",
    "station = \"(02000) cabecera autopista norte\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = data.split_data('data', aggregation = 'day')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments on selecting the right transformation\n",
    "\n",
    "The motivation to do this experiments is to be able to select the best transformation to the data. \n",
    "We explore log, standarization, and minmax transformations (and combiantion of them). \n",
    "\n",
    "Unfortunatly, since transformation will lead to diferent scales, traditional metrics such as AIC, log-likelihood, BIC cannot be compared. To select the best transformation, I take into account the MAPE metric with a 7 days prediction, and the running time. \n",
    "\n",
    "For each transformation, we fit a model using pm.auto_arima which selects the best model with give hyperparameters. To compare model with different transformation, we only use the best model of the auto_arima function. For this function, the selection criteria is the AIC. \n",
    "\n",
    "I took one station (porta norte) and transformed the data. Regular standarization is the one that has the best performance. The MAPE is 0.13 compared to 0.25 of the second best model (log transformation). Also, compared to the second best model, the running time to fir the model is X3 times faster. \n",
    "\n",
    "More research: I would need to figure out if the same transformation has similar results with other stations. For now I have only tested one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    return (x - np.mean(x))/(np.std(x))\n",
    "\n",
    "def normalize1(x):\n",
    "    return (x - np.min(x))/(np.max(x) - np.min(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "def APE(target, predicted):\n",
    "    return np.abs((target - predicted) / target)\n",
    "\n",
    "def mape(target, predicted, axis = None):\n",
    "    return np.mean(APE(target, predicted), axis = axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_raw = train[station]\n",
    "s_log = s_raw.transform(np.log1p)\n",
    "s_log_nor = normalize(s_log)\n",
    "s_nor = normalize(s_raw)\n",
    "s_log_nor1 = normalize1(s_log)\n",
    "s_nor1 = normalize1(s_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.926056146621704\n",
      "65.68860793113708\n",
      "2.1380200386047363\n",
      "20.929821014404297\n",
      "4.973753213882446\n",
      "3.901477336883545\n"
     ]
    }
   ],
   "source": [
    "# Raw model \n",
    "s_data = [s_raw, s_log, s_log_nor, s_nor, s_log_nor1, s_nor1]\n",
    "models = []\n",
    "test_size = 7\n",
    "for s in s_data:\n",
    "    start = time.time()\n",
    "    model = pm.auto_arima(s, start_p=2, start_q=2, max_p=7, max_q=7, seasonal=False,\n",
    "                        stepwise=True, suppress_warnings=True, error_action='ignore', d = 0, \n",
    "                        maxiter = 200, out_of_sample_size = test_size, scoring = 'mse')\n",
    "    models.append(model)\n",
    "    end = time.time()\n",
    "    print (end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log transformation took 65 seconds, and stadarition took 20 seconds. The are the second and first best models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0 - Raw MAPE: 0.24128880092487925\n",
      "Model 1 - log MAPE: 0.21380937184363305\n",
      "Model 3 - nor MAPE: 0.13745761654768238\n",
      "Model 4 - log_nor1 MAPE: 0.24608887583088443\n",
      "Model 5 - nor1 MAPE: 0.24122682803419906\n"
     ]
    }
   ],
   "source": [
    "target = np.array(s_raw[-test_size:])\n",
    "#Model 0\n",
    "p50_raw = models[0].oob_preds_\n",
    "print ('Model 0 - Raw MAPE:', mape(target, p50_raw))\n",
    "\n",
    "#Model 1\n",
    "p50_log = np.expm1(models[1].oob_preds_)\n",
    "print ('Model 1 - log MAPE:', mape(target, p50_log))\n",
    "\n",
    "#Model 2 \n",
    "\n",
    "#Model 3\n",
    "p50_nor = (models[3].oob_preds_ * s_raw.std()) + s_raw.mean()\n",
    "print ('Model 3 - nor MAPE:', mape(target, p50_nor))\n",
    "\n",
    "#Model 4 \n",
    "p50_log_nor1 = np.expm1(models[4].oob_preds_ * (s_log.max() - s_log.min()) + s_log.min())\n",
    "print ('Model 4 - log_nor1 MAPE:', mape(target, p50_log_nor1))\n",
    "\n",
    "#Model 5\n",
    "p50_nor1 = (models[5].oob_preds_ * (s_raw.max() - s_raw.min())) + s_raw.min()\n",
    "print ('Model 5 - nor1 MAPE:', mape(target, p50_nor1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting 20 time steps into the future: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values to keep in mind \n",
    "mean = s_raw.mean()\n",
    "std = s_raw.std()\n",
    "max_raw = s_raw.max()\n",
    "min_raw = s_raw.min()\n",
    "\n",
    "max_log = s_log.mean()\n",
    "min_log = s_log.mean()\n",
    "forecast_period = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Measure the forcasting error of 20 predicitions\n",
    "total_forcast_period = 20\n",
    "target = test[station][:total_forcast_period]\n",
    "\n",
    "t_raw = test[station][:total_forcast_period]\n",
    "t_log = t_raw.transform(np.log1p)\n",
    "t_log_nor = (t_log - s_log.mean())/(s_log.std())\n",
    "t_nor = (t_raw - s_raw.mean())/(s_raw.std())\n",
    "t_log_nor1 = (t_log - s_log.min())/(s_log.max() - s_log.min())\n",
    "t_nor1 = (t_raw - s_raw.min())/(s_raw.max() - s_raw.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(model, target, forecast_period = 1):\n",
    "    prediction_list = []\n",
    "    for t in target:\n",
    "        p = model.predict(forecast_period)\n",
    "        prediction_list.append(p)\n",
    "        model.update(t)\n",
    "    return np.array(prediction_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 0 \n",
    "p20_raw = prediction(models[0], t_raw, forecast_period = 1)\n",
    "\n",
    "#Model 1 \n",
    "p20_log = prediction(models[1], t_log, forecast_period = 1)\n",
    "p20_log =  np.expm1(p20_log)\n",
    "\n",
    "#Model 2\n",
    "# p20_log_nor = prediction(models[2], t_log_nor, forecast_period = 1)\n",
    "# Ignore model 2\n",
    "\n",
    "#Model 3\n",
    "p20_nor = prediction(models[3], t_nor, forecast_period = 1)\n",
    "p20_nor = (p20_nor*s_raw.std())+ s_raw.mean()\n",
    "\n",
    "#Model 4 \n",
    "p20_log_nor1 = prediction(models[4], t_log_nor1, forecast_period = 1)\n",
    "p20_log_nor1 = np.expm1(p20_log_nor1*(max_log - min_log) + min_log)\n",
    "\n",
    "#Model 5\n",
    "p20_nor1 = prediction(models[5], t_nor1, forecast_period = 1)\n",
    "p20_nor1 = (p20_nor1*(s_raw.max() - s_raw.min())) + (s_raw.min())\n",
    "\n",
    "# (t_raw - s_raw.min())/(s_raw.max() - s_raw.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0 - Raw MAPE: 0.35637711614881107\n",
      "Model 1 - log MAPE: 0.3016776303962018\n",
      "Model 3 - nor MAPE: 0.25350074254782845\n",
      "Model 4 - log_nor1 MAPE: 0.38677325679848945\n",
      "Model 5 - nor1 MAPE: 0.35635911311489044\n"
     ]
    }
   ],
   "source": [
    "print ('Model 0 - Raw MAPE:', mape(target, p20_raw.flatten()))\n",
    "print ('Model 1 - log MAPE:', mape(target, p20_log.flatten()))\n",
    "print ('Model 3 - nor MAPE:', mape(target, p20_nor.flatten()))\n",
    "print ('Model 4 - log_nor1 MAPE:', mape(target, p20_log_nor1.flatten()))\n",
    "print ('Model 5 - nor1 MAPE:', mape(target, p20_nor1.flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check full results for One station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.ones(shape = (3,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "list"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('prediction': conda)",
   "name": "python388jvsc74a57bd09156c5fe81c128768729ffddff8e92efa661f491c3f6eae9c54847e138d37eca"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}